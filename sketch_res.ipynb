{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import slack_notification as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SketchResModel(nn.Module):\n",
    "    \"\"\"\n",
    "    https://github.com/HPrinz/sketch-recognition\n",
    "    input size: (225. 225)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SketchResModel, self).__init__()\n",
    "        self.output_num = 10\n",
    "        self.filer_num = 64\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "        self.conv1 = self.conv_block(1, self.filer_num*1, kernel_size=15, stride=3, padding=0, act_fn=self.act)\n",
    "        self.conv2 = self.conv_block(self.filer_num*1, self.filer_num*2, kernel_size=3, stride=1, padding=0, act_fn=self.act)\n",
    "        self.conv3 = self.conv_block(self.filer_num*2, self.filer_num*4, kernel_size=3, stride=1, padding=1, act_fn=self.act)\n",
    "        self.conv4 = self.conv_block(self.filer_num*4, self.filer_num*4, kernel_size=3, stride=1, padding=1, act_fn=self.act)\n",
    "        self.conv5 = self.conv_block(self.filer_num*4, self.filer_num*4, kernel_size=3, stride=1, padding=1, act_fn=self.act)\n",
    "        self.conv6 = self.conv_block(self.filer_num*4, self.filer_num*8, kernel_size=7, stride=1, padding=0, act_fn=self.act)\n",
    "        self.conv7 = self.conv_block(self.filer_num*8, self.filer_num*8, kernel_size=1, stride=1, padding=0, act_fn=self.act)\n",
    "        self.conv8 = self.conv_block(self.filer_num*8, 50, kernel_size=1, stride=1, padding=0, act_fn=self.act)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(50, self.output_num),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        self.drop = nn.Dropout2d(p=0.25)\n",
    "        \n",
    "        self.res_block = nn.Sequential(\n",
    "            self.conv_block(self.filer_num*2, self.filer_num*4, kernel_size=3, stride=1, padding=1, act_fn=self.act),\n",
    "            self.conv_block(self.filer_num*4, self.filer_num*4, kernel_size=3, stride=1, padding=1, act_fn=self.act),\n",
    "            nn.Conv2d(self.filer_num*4, self.filer_num*4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(self.filer_num*4),\n",
    "        )\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(self.filer_num*2, self.filer_num*4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(self.filer_num*4),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        h = self.pool(self.conv1(input))\n",
    "        h = self.pool(self.conv2(h))\n",
    "        #h = self.pool(self.conv5(self.conv4(self.conv3(h))))\n",
    "        h1 = self.residual(h)\n",
    "        h = self.pool(self.act(self.res_block(h) + h1))\n",
    "        h = self.drop(self.conv6(h))\n",
    "        h = self.conv8(self.drop(self.conv7(h)))\n",
    "        h = self.out(self.flatten(h))\n",
    "        return h\n",
    "    \n",
    "    def conv_block(self, in_dim, out_dim, kernel_size, stride, padding, act_fn):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            act_fn,\n",
    "        )\n",
    "    \n",
    "    def flatten(self, x):\n",
    "        bs = x.size()[0]\n",
    "        return x.view(bs, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(225),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_transform_2 = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(250),\n",
    "    transforms.RandomCrop(225),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_transform_3 = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(225),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root='./train', transform=data_transform_3)\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                          batch_size=4,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)    \n",
    "test_data = torchvision.datasets.ImageFolder(root='./test', transform=data_transform_3)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                          batch_size=4,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SketchResModel().cuda()\n",
    "lr = 1e-4\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_plot(train_loss, test_loss, name):\n",
    "    epoch = np.arange(len(train_loss))\n",
    "    plt.clf()\n",
    "    plt.plot(epoch, train_loss, label='train')\n",
    "    plt.plot(epoch, test_loss, label='test')\n",
    "    plt.legend()\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.savefig('./models/{}/loss.png'.format(name))\n",
    "    sn.upload_image('./models/{}/loss.png'.format(name))\n",
    "        \n",
    "def train(epoch, name, send=True, init_epoch=0):\n",
    "    \n",
    "    if not os.path.exists('models/' + name):\n",
    "        os.mkdir('models/'+name)\n",
    "    train_loss = np.array([])\n",
    "    test_loss = np.array([])\n",
    "    for i in range(epoch):\n",
    "        \n",
    "        loss_per_epoch = 0\n",
    "        acc = 0\n",
    "        for batch_idx, (imgs, labels) in enumerate(train_data_loader):\n",
    "            model.train()\n",
    "            optim.zero_grad()\n",
    "            imgs = imgs.cuda().float()\n",
    "            labels = labels.cuda().long()\n",
    "            estimated = model.forward(imgs)\n",
    "            loss = criterion(estimated, labels)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            loss_per_epoch += loss.data\n",
    "            acc += torch.sum(labels == torch.argmax(estimated, dim=1)).cpu().numpy()\n",
    "            \n",
    "        train_loss = np.append(train_loss, loss_per_epoch)\n",
    "        print(\"epoch: {}, train_loss: {}\".format(i, train_loss[-1]))\n",
    "        print(\"train_acc: {}\".format(acc/len(train_data)))\n",
    "        if send:\n",
    "            sn.send_notification(\"epoch: {}, train_loss: {}\".format(i, train_loss[-1]))\n",
    "            sn.send_notification(\"train_acc: {}\".format(acc/len(train_data)))\n",
    "    \n",
    "        loss_per_epoch = 0\n",
    "        acc = 0\n",
    "        for batch_idx, (imgs, labels) in enumerate(test_data_loader):\n",
    "            model.eval()\n",
    "            imgs = imgs.cuda().float()\n",
    "            labels = labels.cuda().long()\n",
    "            estimated = model.forward(imgs)\n",
    "            loss = criterion(estimated, labels)\n",
    "            loss_per_epoch += loss.data*len(train_data)/len(test_data)\n",
    "            acc += torch.sum(labels == torch.argmax(estimated, dim=1)).cpu().numpy()\n",
    "            \n",
    "        test_loss = np.append(test_loss, loss_per_epoch)\n",
    "        print(\"epoch: {}, test_loss: {}\".format(i, test_loss[-1]))\n",
    "        print(\"test_acc: {}\".format(acc/len(test_data)))\n",
    "        if send:\n",
    "            sn.send_notification(\"epoch: {}, test_loss: {}\".format(i, test_loss[-1]))\n",
    "            sn.send_notification(\"test_acc: {}\".format(acc/len(test_data)))\n",
    "        loss_plot(train_loss, test_loss, name)\n",
    "        \n",
    "        torch.save(model.state_dict(), './models/{}/epoch_{}.pth'.format(name, i+init_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 396.00286865234375\n",
      "train_acc: 0.27\n",
      "epoch: 0, test_loss: 391.22021484375\n",
      "test_acc: 0.49\n",
      "epoch: 1, train_loss: 390.40289306640625\n",
      "train_acc: 0.3842857142857143\n",
      "epoch: 1, test_loss: 386.78143310546875\n",
      "test_acc: 0.63\n",
      "epoch: 2, train_loss: 385.9722900390625\n",
      "train_acc: 0.45571428571428574\n",
      "epoch: 2, test_loss: 382.5222473144531\n",
      "test_acc: 0.64\n",
      "epoch: 3, train_loss: 380.92205810546875\n",
      "train_acc: 0.5128571428571429\n",
      "epoch: 3, test_loss: 375.5458984375\n",
      "test_acc: 0.67\n",
      "epoch: 4, train_loss: 378.94873046875\n",
      "train_acc: 0.5128571428571429\n",
      "epoch: 4, test_loss: 376.25067138671875\n",
      "test_acc: 0.62\n",
      "epoch: 5, train_loss: 374.15594482421875\n",
      "train_acc: 0.57\n",
      "epoch: 5, test_loss: 371.55517578125\n",
      "test_acc: 0.6\n",
      "epoch: 6, train_loss: 371.5858154296875\n",
      "train_acc: 0.56\n",
      "epoch: 6, test_loss: 364.92205810546875\n",
      "test_acc: 0.69\n",
      "epoch: 7, train_loss: 366.5924377441406\n",
      "train_acc: 0.6442857142857142\n",
      "epoch: 7, test_loss: 363.08935546875\n",
      "test_acc: 0.71\n",
      "epoch: 8, train_loss: 363.7070617675781\n",
      "train_acc: 0.6314285714285715\n",
      "epoch: 8, test_loss: 361.0901184082031\n",
      "test_acc: 0.71\n",
      "epoch: 9, train_loss: 360.3836975097656\n",
      "train_acc: 0.6542857142857142\n",
      "epoch: 9, test_loss: 358.0908508300781\n",
      "test_acc: 0.77\n",
      "epoch: 10, train_loss: 358.2161865234375\n",
      "train_acc: 0.6414285714285715\n",
      "epoch: 10, test_loss: 357.57147216796875\n",
      "test_acc: 0.67\n",
      "epoch: 11, train_loss: 353.662353515625\n",
      "train_acc: 0.6728571428571428\n",
      "epoch: 11, test_loss: 353.51104736328125\n",
      "test_acc: 0.67\n",
      "epoch: 12, train_loss: 351.4224853515625\n",
      "train_acc: 0.6728571428571428\n",
      "epoch: 12, test_loss: 348.6336364746094\n",
      "test_acc: 0.69\n",
      "epoch: 13, train_loss: 349.1340026855469\n",
      "train_acc: 0.6928571428571428\n",
      "epoch: 13, test_loss: 346.60369873046875\n",
      "test_acc: 0.76\n",
      "epoch: 14, train_loss: 344.18035888671875\n",
      "train_acc: 0.73\n",
      "epoch: 14, test_loss: 344.071533203125\n",
      "test_acc: 0.74\n",
      "epoch: 15, train_loss: 339.9618225097656\n",
      "train_acc: 0.7642857142857142\n",
      "epoch: 15, test_loss: 339.17138671875\n",
      "test_acc: 0.81\n",
      "epoch: 16, train_loss: 338.05572509765625\n",
      "train_acc: 0.74\n",
      "epoch: 16, test_loss: 355.057861328125\n",
      "test_acc: 0.51\n",
      "epoch: 17, train_loss: 334.76629638671875\n",
      "train_acc: 0.7657142857142857\n",
      "epoch: 17, test_loss: 339.80743408203125\n",
      "test_acc: 0.77\n",
      "epoch: 18, train_loss: 331.5573425292969\n",
      "train_acc: 0.7671428571428571\n",
      "epoch: 18, test_loss: 336.6521301269531\n",
      "test_acc: 0.75\n",
      "epoch: 19, train_loss: 327.34075927734375\n",
      "train_acc: 0.7942857142857143\n",
      "epoch: 19, test_loss: 337.6590576171875\n",
      "test_acc: 0.75\n",
      "epoch: 20, train_loss: 326.1625671386719\n",
      "train_acc: 0.8042857142857143\n",
      "epoch: 20, test_loss: 330.5184631347656\n",
      "test_acc: 0.75\n",
      "epoch: 21, train_loss: 323.02227783203125\n",
      "train_acc: 0.8057142857142857\n",
      "epoch: 21, test_loss: 326.7034912109375\n",
      "test_acc: 0.79\n",
      "epoch: 22, train_loss: 319.865234375\n",
      "train_acc: 0.8371428571428572\n",
      "epoch: 22, test_loss: 324.4275817871094\n",
      "test_acc: 0.78\n",
      "epoch: 23, train_loss: 318.279296875\n",
      "train_acc: 0.8328571428571429\n",
      "epoch: 23, test_loss: 325.9679260253906\n",
      "test_acc: 0.68\n",
      "epoch: 24, train_loss: 313.0026550292969\n",
      "train_acc: 0.87\n",
      "epoch: 24, test_loss: 325.88983154296875\n",
      "test_acc: 0.74\n",
      "epoch: 25, train_loss: 314.9501953125\n",
      "train_acc: 0.83\n",
      "epoch: 25, test_loss: 324.55206298828125\n",
      "test_acc: 0.79\n",
      "epoch: 26, train_loss: 310.0196533203125\n",
      "train_acc: 0.8571428571428571\n",
      "epoch: 26, test_loss: 322.7925109863281\n",
      "test_acc: 0.73\n",
      "epoch: 27, train_loss: 306.12567138671875\n",
      "train_acc: 0.8771428571428571\n",
      "epoch: 27, test_loss: 316.0881042480469\n",
      "test_acc: 0.76\n",
      "epoch: 28, train_loss: 305.2154235839844\n",
      "train_acc: 0.8685714285714285\n",
      "epoch: 28, test_loss: 322.1302795410156\n",
      "test_acc: 0.8\n",
      "epoch: 29, train_loss: 306.0008544921875\n",
      "train_acc: 0.8685714285714285\n",
      "epoch: 29, test_loss: 319.01922607421875\n",
      "test_acc: 0.82\n",
      "epoch: 30, train_loss: 300.71484375\n",
      "train_acc: 0.8885714285714286\n",
      "epoch: 30, test_loss: 318.2726745605469\n",
      "test_acc: 0.73\n",
      "epoch: 31, train_loss: 300.6938171386719\n",
      "train_acc: 0.8942857142857142\n",
      "epoch: 31, test_loss: 329.74755859375\n",
      "test_acc: 0.6\n",
      "epoch: 32, train_loss: 298.8702392578125\n",
      "train_acc: 0.8871428571428571\n",
      "epoch: 32, test_loss: 313.34637451171875\n",
      "test_acc: 0.79\n",
      "epoch: 33, train_loss: 298.21856689453125\n",
      "train_acc: 0.88\n",
      "epoch: 33, test_loss: 314.3295593261719\n",
      "test_acc: 0.74\n",
      "epoch: 34, train_loss: 295.91497802734375\n",
      "train_acc: 0.9042857142857142\n",
      "epoch: 34, test_loss: 311.3001403808594\n",
      "test_acc: 0.75\n",
      "epoch: 35, train_loss: 292.5692138671875\n",
      "train_acc: 0.9142857142857143\n",
      "epoch: 35, test_loss: 311.9671936035156\n",
      "test_acc: 0.78\n",
      "epoch: 36, train_loss: 293.10400390625\n",
      "train_acc: 0.9014285714285715\n",
      "epoch: 36, test_loss: 322.7757568359375\n",
      "test_acc: 0.67\n",
      "epoch: 37, train_loss: 291.49151611328125\n",
      "train_acc: 0.9114285714285715\n",
      "epoch: 37, test_loss: 314.4213562011719\n",
      "test_acc: 0.75\n",
      "epoch: 38, train_loss: 287.89031982421875\n",
      "train_acc: 0.9214285714285714\n",
      "epoch: 38, test_loss: 311.8446044921875\n",
      "test_acc: 0.79\n",
      "epoch: 39, train_loss: 289.95111083984375\n",
      "train_acc: 0.92\n",
      "epoch: 39, test_loss: 311.57379150390625\n",
      "test_acc: 0.78\n",
      "epoch: 0, train_loss: 287.1006164550781\n",
      "train_acc: 0.9257142857142857\n",
      "epoch: 0, test_loss: 305.2470703125\n",
      "test_acc: 0.81\n",
      "epoch: 1, train_loss: 286.9294738769531\n",
      "train_acc: 0.93\n",
      "epoch: 1, test_loss: 307.2428894042969\n",
      "test_acc: 0.84\n",
      "epoch: 2, train_loss: 286.0435791015625\n",
      "train_acc: 0.9285714285714286\n",
      "epoch: 2, test_loss: 305.6487731933594\n",
      "test_acc: 0.82\n",
      "epoch: 3, train_loss: 282.8385925292969\n",
      "train_acc: 0.9528571428571428\n",
      "epoch: 3, test_loss: 303.6551818847656\n",
      "test_acc: 0.85\n",
      "epoch: 4, train_loss: 282.2245178222656\n",
      "train_acc: 0.96\n",
      "epoch: 4, test_loss: 303.43145751953125\n",
      "test_acc: 0.81\n",
      "epoch: 5, train_loss: 283.6748352050781\n",
      "train_acc: 0.9414285714285714\n",
      "epoch: 5, test_loss: 305.5288391113281\n",
      "test_acc: 0.8\n",
      "epoch: 6, train_loss: 283.4665832519531\n",
      "train_acc: 0.9371428571428572\n",
      "epoch: 6, test_loss: 304.02716064453125\n",
      "test_acc: 0.88\n",
      "epoch: 7, train_loss: 285.65728759765625\n",
      "train_acc: 0.9342857142857143\n",
      "epoch: 7, test_loss: 303.6951599121094\n",
      "test_acc: 0.84\n",
      "epoch: 8, train_loss: 284.255126953125\n",
      "train_acc: 0.9314285714285714\n",
      "epoch: 8, test_loss: 305.8025817871094\n",
      "test_acc: 0.84\n",
      "epoch: 9, train_loss: 280.9260559082031\n",
      "train_acc: 0.9614285714285714\n",
      "epoch: 9, test_loss: 305.063720703125\n",
      "test_acc: 0.81\n",
      "epoch: 10, train_loss: 281.51190185546875\n",
      "train_acc: 0.9585714285714285\n",
      "epoch: 10, test_loss: 306.1736755371094\n",
      "test_acc: 0.79\n",
      "epoch: 11, train_loss: 281.4471130371094\n",
      "train_acc: 0.9585714285714285\n",
      "epoch: 11, test_loss: 305.1562194824219\n",
      "test_acc: 0.84\n",
      "epoch: 12, train_loss: 283.8673095703125\n",
      "train_acc: 0.9342857142857143\n",
      "epoch: 12, test_loss: 304.730712890625\n",
      "test_acc: 0.84\n",
      "epoch: 13, train_loss: 282.6173400878906\n",
      "train_acc: 0.9485714285714286\n",
      "epoch: 13, test_loss: 304.6852722167969\n",
      "test_acc: 0.82\n",
      "epoch: 14, train_loss: 281.6844787597656\n",
      "train_acc: 0.9514285714285714\n",
      "epoch: 14, test_loss: 304.34515380859375\n",
      "test_acc: 0.82\n",
      "epoch: 15, train_loss: 279.9036560058594\n",
      "train_acc: 0.9614285714285714\n",
      "epoch: 15, test_loss: 306.5256652832031\n",
      "test_acc: 0.81\n",
      "epoch: 16, train_loss: 280.3290710449219\n",
      "train_acc: 0.9542857142857143\n",
      "epoch: 16, test_loss: 305.1542663574219\n",
      "test_acc: 0.86\n",
      "epoch: 17, train_loss: 281.5545959472656\n",
      "train_acc: 0.9485714285714286\n",
      "epoch: 17, test_loss: 304.0621337890625\n",
      "test_acc: 0.81\n",
      "epoch: 18, train_loss: 280.786376953125\n",
      "train_acc: 0.9614285714285714\n",
      "epoch: 18, test_loss: 302.7044982910156\n",
      "test_acc: 0.85\n",
      "epoch: 19, train_loss: 280.2130126953125\n",
      "train_acc: 0.9528571428571428\n",
      "epoch: 19, test_loss: 303.7331237792969\n",
      "test_acc: 0.8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0079607eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(40, '1204_1', send=True)\n",
    "lr = 1e-5\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "train(20, '1204_1', send=True, init_epoch=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SketchResModel()\n",
    "model.load_state_dict(torch.load('models/1204_1/epoch_48.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.FloatTensor(1, 1, 225, 225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(1, 1, 225, 225)\n",
      "      %1 : Float(64, 1, 15, 15)\n",
      "      %2 : Float(64)\n",
      "      %3 : Float(64)\n",
      "      %4 : Float(64)\n",
      "      %5 : Float(64)\n",
      "      %6 : Float(64)\n",
      "      %7 : Long()\n",
      "      %8 : Float(128, 64, 3, 3)\n",
      "      %9 : Float(128)\n",
      "      %10 : Float(128)\n",
      "      %11 : Float(128)\n",
      "      %12 : Float(128)\n",
      "      %13 : Float(128)\n",
      "      %14 : Long()\n",
      "      %15 : Float(256, 128, 3, 3)\n",
      "      %16 : Float(256)\n",
      "      %17 : Float(256)\n",
      "      %18 : Float(256)\n",
      "      %19 : Float(256)\n",
      "      %20 : Float(256)\n",
      "      %21 : Long()\n",
      "      %22 : Float(256, 256, 3, 3)\n",
      "      %23 : Float(256)\n",
      "      %24 : Float(256)\n",
      "      %25 : Float(256)\n",
      "      %26 : Float(256)\n",
      "      %27 : Float(256)\n",
      "      %28 : Long()\n",
      "      %29 : Float(256, 256, 3, 3)\n",
      "      %30 : Float(256)\n",
      "      %31 : Float(256)\n",
      "      %32 : Float(256)\n",
      "      %33 : Float(256)\n",
      "      %34 : Float(256)\n",
      "      %35 : Long()\n",
      "      %36 : Float(512, 256, 7, 7)\n",
      "      %37 : Float(512)\n",
      "      %38 : Float(512)\n",
      "      %39 : Float(512)\n",
      "      %40 : Float(512)\n",
      "      %41 : Float(512)\n",
      "      %42 : Long()\n",
      "      %43 : Float(512, 512, 1, 1)\n",
      "      %44 : Float(512)\n",
      "      %45 : Float(512)\n",
      "      %46 : Float(512)\n",
      "      %47 : Float(512)\n",
      "      %48 : Float(512)\n",
      "      %49 : Long()\n",
      "      %50 : Float(50, 512, 1, 1)\n",
      "      %51 : Float(50)\n",
      "      %52 : Float(50)\n",
      "      %53 : Float(50)\n",
      "      %54 : Float(50)\n",
      "      %55 : Float(50)\n",
      "      %56 : Long()\n",
      "      %57 : Float(10, 50)\n",
      "      %58 : Float(10)\n",
      "      %59 : Float(256, 128, 3, 3)\n",
      "      %60 : Float(256)\n",
      "      %61 : Float(256)\n",
      "      %62 : Float(256)\n",
      "      %63 : Float(256)\n",
      "      %64 : Float(256)\n",
      "      %65 : Long()\n",
      "      %66 : Float(256, 256, 3, 3)\n",
      "      %67 : Float(256)\n",
      "      %68 : Float(256)\n",
      "      %69 : Float(256)\n",
      "      %70 : Float(256)\n",
      "      %71 : Float(256)\n",
      "      %72 : Long()\n",
      "      %73 : Float(256, 256, 3, 3)\n",
      "      %74 : Float(256)\n",
      "      %75 : Float(256)\n",
      "      %76 : Float(256)\n",
      "      %77 : Float(256)\n",
      "      %78 : Float(256)\n",
      "      %79 : Long()\n",
      "      %80 : Float(256, 128, 3, 3)\n",
      "      %81 : Float(256)\n",
      "      %82 : Float(256)\n",
      "      %83 : Float(256)\n",
      "      %84 : Float(256)\n",
      "      %85 : Float(256)\n",
      "      %86 : Long()) {\n",
      "  %87 : Float(1, 64, 71, 71) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[15, 15], pads=[0, 0, 0, 0], strides=[3, 3]](%0, %1, %2), scope: SketchResModel/Sequential[conv1]/Conv2d[0]\n",
      "  %88 : Float(1, 64, 71, 71) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%87, %3, %4, %5, %6), scope: SketchResModel/Sequential[conv1]/BatchNorm2d[1]\n",
      "  %89 : Float(1, 64, 71, 71) = onnx::LeakyRelu[alpha=0.2](%88), scope: SketchResModel/Sequential[conv1]/LeakyReLU[2]\n",
      "  %90 : Float(1, 64, 35, 35) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%89), scope: SketchResModel/MaxPool2d[pool]\n",
      "  %91 : Float(1, 128, 33, 33) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%90, %8, %9), scope: SketchResModel/Sequential[conv2]/Conv2d[0]\n",
      "  %92 : Float(1, 128, 33, 33) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%91, %10, %11, %12, %13), scope: SketchResModel/Sequential[conv2]/BatchNorm2d[1]\n",
      "  %93 : Float(1, 128, 33, 33) = onnx::LeakyRelu[alpha=0.2](%92), scope: SketchResModel/Sequential[conv2]/LeakyReLU[2]\n",
      "  %94 : Float(1, 128, 16, 16) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%93), scope: SketchResModel/MaxPool2d[pool]\n",
      "  %95 : Float(1, 256, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%94, %80, %81), scope: SketchResModel/Sequential[residual]/Conv2d[0]\n",
      "  %96 : Float(1, 256, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%95, %82, %83, %84, %85), scope: SketchResModel/Sequential[residual]/BatchNorm2d[1]\n",
      "  %97 : Float(1, 256, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%94, %59, %60), scope: SketchResModel/Sequential[res_block]/Sequential[0]/Conv2d[0]\n",
      "  %98 : Float(1, 256, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%97, %61, %62, %63, %64), scope: SketchResModel/Sequential[res_block]/Sequential[0]/BatchNorm2d[1]\n",
      "  %99 : Float(1, 256, 16, 16) = onnx::LeakyRelu[alpha=0.2](%98), scope: SketchResModel/Sequential[res_block]/Sequential[0]/LeakyReLU[2]\n",
      "  %100 : Float(1, 256, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%99, %66, %67), scope: SketchResModel/Sequential[res_block]/Sequential[1]/Conv2d[0]\n",
      "  %101 : Float(1, 256, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%100, %68, %69, %70, %71), scope: SketchResModel/Sequential[res_block]/Sequential[1]/BatchNorm2d[1]\n",
      "  %102 : Float(1, 256, 16, 16) = onnx::LeakyRelu[alpha=0.2](%101), scope: SketchResModel/Sequential[res_block]/Sequential[1]/LeakyReLU[2]\n",
      "  %103 : Float(1, 256, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%102, %73, %74), scope: SketchResModel/Sequential[res_block]/Conv2d[2]\n",
      "  %104 : Float(1, 256, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%103, %75, %76, %77, %78), scope: SketchResModel/Sequential[res_block]/BatchNorm2d[3]\n",
      "  %105 : Float(1, 256, 16, 16) = onnx::Add(%104, %96), scope: SketchResModel\n",
      "  %106 : Float(1, 256, 16, 16) = onnx::LeakyRelu[alpha=0.2](%105), scope: SketchResModel/LeakyReLU[act]\n",
      "  %107 : Float(1, 256, 7, 7) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%106), scope: SketchResModel/MaxPool2d[pool]\n",
      "  %108 : Float(1, 512, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[0, 0, 0, 0], strides=[1, 1]](%107, %36, %37), scope: SketchResModel/Sequential[conv6]/Conv2d[0]\n",
      "  %109 : Float(1, 512, 1, 1) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%108, %38, %39, %40, %41), scope: SketchResModel/Sequential[conv6]/BatchNorm2d[1]\n",
      "  %110 : Float(1, 512, 1, 1) = onnx::LeakyRelu[alpha=0.2](%109), scope: SketchResModel/Sequential[conv6]/LeakyReLU[2]\n",
      "  %111 : Float(1, 512, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%110, %43, %44), scope: SketchResModel/Sequential[conv7]/Conv2d[0]\n",
      "  %112 : Float(1, 512, 1, 1) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%111, %45, %46, %47, %48), scope: SketchResModel/Sequential[conv7]/BatchNorm2d[1]\n",
      "  %113 : Float(1, 512, 1, 1) = onnx::LeakyRelu[alpha=0.2](%112), scope: SketchResModel/Sequential[conv7]/LeakyReLU[2]\n",
      "  %114 : Float(1, 50, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%113, %50, %51), scope: SketchResModel/Sequential[conv8]/Conv2d[0]\n",
      "  %115 : Float(1, 50, 1, 1) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%114, %52, %53, %54, %55), scope: SketchResModel/Sequential[conv8]/BatchNorm2d[1]\n",
      "  %116 : Float(1, 50, 1, 1) = onnx::LeakyRelu[alpha=0.2](%115), scope: SketchResModel/Sequential[conv8]/LeakyReLU[2]\n",
      "  %117 : Dynamic = onnx::Shape(%116), scope: SketchResModel\n",
      "  %118 : Dynamic = onnx::Slice[axes=[0], ends=[1], starts=[0]](%117), scope: SketchResModel\n",
      "  %119 : Long() = onnx::Squeeze[axes=[0]](%118), scope: SketchResModel\n",
      "  %120 : Long() = onnx::Constant[value={-1}](), scope: SketchResModel\n",
      "  %121 : Dynamic = onnx::Unsqueeze[axes=[0]](%119), scope: SketchResModel\n",
      "  %122 : Dynamic = onnx::Unsqueeze[axes=[0]](%120), scope: SketchResModel\n",
      "  %123 : Dynamic = onnx::Concat[axis=0](%121, %122), scope: SketchResModel\n",
      "  %124 : Float(1, 50) = onnx::Reshape(%116, %123), scope: SketchResModel\n",
      "  %125 : Float(1, 10) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%124, %57, %58), scope: SketchResModel/Sequential[out]/Linear[0]\n",
      "  %126 : Float(1, 10) = onnx::Sigmoid(%125), scope: SketchResModel/Sequential[out]/Sigmoid[1]\n",
      "  return (%126);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model, dummy_input, 'SketchResModel.proto', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onnx.load('SketchResModel.proto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Keras version 2.2.4 detected. Last version known to be fully compatible of Keras is 2.1.6 .\n",
      "WARNING:root:TensorFlow version 1.12.0 detected. Last version known to be fully compatible is 1.5.0 .\n"
     ]
    }
   ],
   "source": [
    "from onnx_coreml import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/33: Converting Node Type Conv\n",
      "2/33: Converting Node Type BatchNormalization\n",
      "3/33: Converting Node Type LeakyRelu\n",
      "4/33: Converting Node Type MaxPool\n",
      "5/33: Converting Node Type Conv\n",
      "6/33: Converting Node Type BatchNormalization\n",
      "7/33: Converting Node Type LeakyRelu\n",
      "8/33: Converting Node Type MaxPool\n",
      "9/33: Converting Node Type Conv\n",
      "10/33: Converting Node Type BatchNormalization\n",
      "11/33: Converting Node Type Conv\n",
      "12/33: Converting Node Type BatchNormalization\n",
      "13/33: Converting Node Type LeakyRelu\n",
      "14/33: Converting Node Type Conv\n",
      "15/33: Converting Node Type BatchNormalization\n",
      "16/33: Converting Node Type LeakyRelu\n",
      "17/33: Converting Node Type Conv\n",
      "18/33: Converting Node Type BatchNormalization\n",
      "19/33: Converting Node Type Add\n",
      "20/33: Converting Node Type LeakyRelu\n",
      "21/33: Converting Node Type MaxPool\n",
      "22/33: Converting Node Type Conv\n",
      "23/33: Converting Node Type BatchNormalization\n",
      "24/33: Converting Node Type LeakyRelu\n",
      "25/33: Converting Node Type Conv\n",
      "26/33: Converting Node Type BatchNormalization\n",
      "27/33: Converting Node Type LeakyRelu\n",
      "28/33: Converting Node Type Conv\n",
      "29/33: Converting Node Type BatchNormalization\n",
      "30/33: Converting Node Type LeakyRelu\n",
      "31/33: Converting Node Type Reshape\n",
      "32/33: Converting Node Type Gemm\n",
      "33/33: Converting Node Type Sigmoid\n",
      "Translation to CoreML spec completed. Now compiling the CoreML model.\n",
      "Model Compilation done.\n"
     ]
    }
   ],
   "source": [
    "coreml_model = convert(\n",
    "    model,\n",
    "    'classifier',\n",
    "    image_input_names=['input'],\n",
    "    image_output_names=['output'],\n",
    "    class_labels=[i for i in range(10)],\n",
    ")\n",
    "coreml_model.save('SketchResModel.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
